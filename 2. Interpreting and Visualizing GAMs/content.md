$public=true$

# 2. Interpreting and Visualizing GAMs

$wide$
from ["Interpreting and Visualizing GAMs" by Noam Ross](https://noamross.github.io/gams-in-r-course/chapter2)
$/wide$

$p=1$

## Interpreting GAM outputs

focus
- interpreting results
- understanding the relationship between variables

### GAM summaries

`summary()`
- gives a summary of the model statistics

$code$
**Example summary**

```r
mod_hwy <- gam(hw.mpg ~ s(weight) + s(rpm) + 
               s(price) + s(comp.ratio) +
               s(width) + fuel + cylinders,
               data = mpg, method = "REML")
summary(mod_hwy)
```

$widec$
$down
$/widec$

```r
Family: gaussian
Link function: identity

Formula:
hw.mpg ~ s(weight) + s(rpm) + s(price) + s(comp.ratio) +
  s(width) + fuel

Parametric coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   23.873      3.531   6.760 1.89e-10 ***
fuelgas        7.571      3.922   1.931   0.0551 .
 ---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

Approximate significance of smooth terms:
                edf Ref.df      F  p-value
s(weight)     6.254  7.439 20.909  < 2e-16 ***
s(rpm)        7.499  8.285  8.534 2.07e-09 ***
s(price)      2.681  3.421  1.678    0.155
s(comp.ratio) 1.000  1.001 18.923 2.22e-05 ***
s(width)      1.001  1.001  0.357    0.551
```
$/code$

### Model information

$code$
```r
Family: gaussian
Link function: identity

Formula:
hw.mpg ~ s(weight) + s(rpm) + s(price) +
  s(comp.ratio) + s(width) + fuel
```

- description of the model we fit
	1. `Family`: model assumes a `gaussian`/normal distribution of our errors
	2. `Link`: `identity` -> the model doesn't transofrm the predictions
	3. Model formula
$/code$

### Parametric terms

parametric
- models that have a pre-determined form
- here: ==linear terms==

$code$
```r
Parametric coefficients:
            Estimate Std. Error t value Pr(>|t|)
(Intercept)   23.873      3.531   6.760 1.89e-10 ***
fuelgas        7.571      3.922   1.931   0.0551 .
 ---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 '
```

1. coefficients for the linear terms in the model
2. values for linear terms
3. errors
4. test statistics
5. p-values
$/code$

### Smooth terms

$info$
For smooths, ==coefficients are not printed==. This is because ==each smooth has several coefficients== - one for each basis function.
$/info$

$code$
```r
Approximate significance of smooth terms:
                edf Ref.df      F  p-value
s(weight)     6.254  7.439 20.909  < 2e-16 ***
s(rpm)        7.499  8.285  8.534 2.07e-09 ***
s(price)      2.681  3.421  1.678    0.155
s(comp.ratio) 1.000  1.001 18.923 2.22e-05 ***
s(width)      1.001  1.001  0.357    0.551
 ---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
```

1. `edf` = ==effective degrees of freedom==
	- represents ==complexity of the smooth==
	- 1 = straight line
	- 2 = quadratic curve
	- ==higher edf = wigglier curve==

$gallery$
![Image](img$pmd6)

|weight|comp.ratio|
|---|---|
|edf ~= 6|edf = 1|
$/gallery$

2. `Ref.df`, `F` = test statistics used in an ANOVA test to test overall significance of the smooth
3. `p-value`

$warn$
These values are approximate, and it's important to visualize your model to check them.
$/warn$
$/code$

### Interpreting significance for smooth terms

significance for smooth terms
- when you cannot draw a horizontal line through the 95% confidence interval
- ($see $down)

$gallery$
```r
Approximate significance of smooth terms:
                edf Ref.df      F  p-value
s(weight)     6.254  7.439 20.909  < 2e-16 ***  <--
s(rpm)        7.499  8.285  8.534 2.07e-09 ***  
s(price)      2.681  3.421  1.678    0.155      <--
s(comp.ratio) 1.000  1.001 18.923 2.22e-05 ***
s(width)      1.001  1.001  0.357    0.551      
```

![Image](img$tlpb)

- horizontal line fits through price curve, not through weight curve!
$/gallery$

$warn$
High EDF doesn't mean significance or vice-versa. A smooth may be linear and significant, non-linear and non-significant, or one of each.

```r
Approximate significance of smooth terms:
                edf Ref.df      F  p-value
s(weight)     6.254  7.439 20.909  < 2e-16 ***  
s(rpm)        7.499  8.285  8.534 2.07e-09 ***  
s(price)      2.681  3.421  1.678    0.155      <--
s(comp.ratio) 1.000  1.001 18.923 2.22e-05 ***  <--
s(width)      1.001  1.001  0.357    0.551      <--
```

$gallery$
![Image](img$avch)
$/gallery$
$/warn$

$p=3$

## Visualising GAMs

visualisation
- one of the most important things to do when interpreting and checking models
- inspect models, gain intuition for model relationships

### Partial effect plots

#### About partial effect plots

partial effect plots
- plots generated by mgcv's `plot`
- show the ==component effect== of each of the smooth or linear terms in the model
	- they each ==add up to the overall prediction==

$code$
```r
plot(gam_model)
```

$gallery$
![Image](img$6ppd)
$/gallery$
$/code$

#### Selecting partial effects

partial effect selection
- default: *all* effects are selected

combining
- normally, each plot gets its own page
- `pages` -> decide how many total pages to spread plots across
- `pages=1` -> show all partial effects together

seeing all plots
- default: only *smooth* plots
- all plots: `all.terms=TRUE` -> displays partial effects of linear or categorical terms

$code$
```r
plot(gam_model, select = c(2, 3))
plot(gam_model, pages = 1)
plot(gam_model, pages = 1, all.terms = TRUE)
```

$gallery$
![Image](img$23ki)
$/gallery$
$/code$

### Showing data on the plots

#### Rug

`rug` argument
- put x values along the bottom of the plot

$code$
```r
plot(gam_model, rug = TRUE)
```

$widec$
$down
$/widec$

$gallery$
![Image](img$fy6m)
$/gallery$
$/code$

#### Residuals

`residuals` argument
- puts partial residuals ont he plots
- partial residuals = the difference between partial effect and the data (after all other partial effects have been accounted for)

$code$
```r
plot(gam_model, residuals = TRUE)
```

$widec$
$down
$/widec$

$gallery$
![Image](img$npn5)
$/gallery$
$/code$

$code$
**Changing residuals shape and size**

```r
plot(gam_model, rug = TRUE, residuals = TRUE,
     pch = 1, cex = 1)
```

- `pch`: changes the shape of the residuals points
- `cex`: changes the size of the residuals points

$widec$
$down
$/widec$

$gallery$
![Image](img$epts)
$/gallery$
$/code$

### Showing standard errors

#### About standard errors

standard errors
- the 95% confidence interval for the mean shape of the effect
- enabled by default

$code$
```r
plot(gam_model, se = TRUE)
```

$widec$
$down
$/widec$

$gallery$
![Image](img$stg2)
$/gallery$
$/code$

#### Styling

$code$
**Shaded confidence intervals**

```r
plot(gam_model, shade = TRUE)
```

$widec$
$down
$/widec$

$gallery$
![Image](img$uc5p)
$/gallery$
$/code$

$code$
**Colourful confidence intervals**

```r
plot(gam_model, shade = TRUE, shade.col = "lightblue")
```

$widec$
$down
$/widec$

$gallery$
![Image](img$9fdz)
$/gallery$
$/code$

#### Including standard errors of the model intercept

including intercept SE
- confidence intervals at the mean value of a variable can be very tiny
	- no real reflection of overall uncertainty in the model
- `seWithMean`: adds in lost uncertainty

$code$
**Transformed Standard Errors**

```r
plot(gam_model, seWithMean = TRUE)
```

$widec$
$down
$/widec$

$gallery$
![Image](img$7cry)
$/gallery$
$/code$

including intercept
- useful -> changes the y-axis
- shows us prediction of the output, assuming other variables are at their average value

$code$
**Shift scale to include intercept**

```r
plot(gam_model, seWithMean = TRUE,
	shift = coef(gam_model)[1])
```

$widec$
$down
$/widec$

$gallery$
![Image](img$fs0d)
$/gallery$
$/code$

$p=7$

## Model checking with `gam.check()` (inadequate basis number)

number of basis functions
- determines how ==wiggly== a smooth can be
- not enough basis functions? smooth may not be wiggly enough to capture the relationships in data

$example$
**Smooth with 4 basis functions**

```r
mod <- gam(y ~ s(x1, k = 4) + s(x2, k = 4),
           data = check_data, method = "REML")
```

$gallery$
![Image](img$ppsj)
$/gallery$

$wide$
- => ==not enough== to capture the pattern
$/wide$
$/example$

$widec$
$down

How do we check whether we have adequate basis functions?
$/widec$

### `gam.check()` written output

`gam.check()`
- provides several outputs

#### Console output

$code$
```r
gam.check(mod)
```

$widec$
$down
$/widec$

```r
Method: REML   Optimizer: outer newton
full convergence after 9 iterations.
Gradient range [-0.0001467222,0.00171085]
(score 784.6012 & scale 2.868607).
Hessian positive definite, eigenvalue range [0.00014,198.5]
Model rank =  7 / 7 
 
Basis dimension (k) checking results. Low p-value
(k-index<1) may indicate that k is too low, especially
if edf is close to k'.
 
        k'  edf k-index p-value    
s(x1) 3.00 1.00    0.35  <2e-16 ***
s(x2) 3.00 2.88    1.00    0.52    
 ---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1
```
$/code$

##### Model convergence

`convergence`
- has R found a best solution?

$code$
```r
Method: REML   Optimizer: outer newton
full convergence after 9 iterations.
Gradient range [-0.0001467222,0.00171085]
(score 784.6012 & scale 2.868607).
Hessian positive definite, eigenvalue range [0.00014,198.5]
Model rank =  7 / 7 
```

- here: `full convergence` -> R has found a best solution
$/code$

$warn$
If the model has not converged, results are likely not correct. this can happen when there are ==too many parameters in the model for not enough data.==
$/warn$

##### Table of basis checking results

basis checking results
- shows a statistical test for patterns in model residuals
- these residuals should be **random!**
- each line = test result for one smooth

$code$
```r
Basis dimension (k) checking results. Low p-value
(k-index<1) may indicate that k is too low, especially
if edf is close to k'.

        k'  edf k-index p-value    
s(x1) 3.00 1.00    0.35  <2e-16 ***
s(x2) 3.00 2.88    1.00    0.52    
 ---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1
```
$/code$

|k'|effective degrees of freedom|test statistic|p-value|
|---|---|---|---|
|number of basis functions|complexity of the smooth|ANOVA statistic|significance|

p-value meaning
- significance? => residuals are ==not randomly distributed==
- => (probably) ==not enough basis functions==

$warn$
This is an approximate test. Always visualize your results too, and compare the k and edf values in addition to looking at the p-value.
$/warn$

$example$
**Fixing the problem**

```r
mod <- gam(y ~ s(x1, k = 12) + s(x2, k = 4),
                data = dat, method = "REML")
gam.check(mod)
```

$widec$
$down
$/widec$

```r
...
 
         k'   edf k-index p-value  
s(x1) 11.00 10.85    1.05   0.830  
s(x2)  3.00  2.98    0.89   0.015 *
 
...
```

- refit with higher k for s(x1) -> problem has disappeared
- /!\ now we see a problem with the _second_ smooth - the p-value for its test is now significant

$warn$
Fixing one problem can reveal another. It is always important to ==re-run `gam.check` after changing models==.

We again increase the k value, this time for the second smooth. Now, both smooths pass the test.

```r
mod <- gam(y ~ s(x1, k = 12) + s(x2, k = 12),
            data = dat, method = "REML")
gam.check(mod)
```

$widec$
$down
$/widec$

```r
...
         k'   edf k-index p-value
s(x1) 11.00 10.86    1.08    0.94
s(x2) 11.00  7.78    0.94    0.12
...
```
$/warn$
$/example$

### `gam.check()` visual output

visual output of `gam.check()`
- four plots
- each gives a different way of looking at your model residuals

$gallery$
![Image](img$23p3)
$/gallery$

$acco$
**1.** ==QQ plot==  
(top left)
- compares the model residuals to a normal distribution
- well-fit model's residuals will be close to a <u>straight line</u>

**2.** ==histogram of residuals==  
(bottom left)
- we expect a symmetrical bell shape

**3.** ==plot of residual values==  
(top right)
- should be evenly distributed around zero

**4.** ==response against fitted values==  
(bottom right)
- perfect model would form a straight line
- /!\ we don't expect a perfect model, but we do expect the pattern to cluster around the 1-to-1 line
$/acco$

$gallery port$
**Comparison: bad model and final model**

$widec$
![Image](img$23p3)
![Image](img$d4pd)
$/widec$

- QQ plot no longer curves
- histogram is bell-shaped
- comparison of response vs. fitted values clusters around a 1-to-1 line
- => indication of a much better model fit
$/gallery port$

$p=10$

## Checking concurvity

### Recap: collinearity

collinearity  
(linear modelling)
- when two variables or covariates in a model are strongly ==correlated==, it's ==difficult to fit the model, because the outcome variable could be responding to either one==
- can result in poorly fit models with large confidence intervals

$info$
In general, we avoid putting multiple collinear variables into the same model.
$/info$

$widec$
$down GAMs
$/widec$

$gallery$
**Covariates: length, width, and height of cars**

![Image](img$pupv)

- strong collinearity between car length and width
- => hard to distinguish between their effects on car efficiency
$/gallery$

### What is concurvity?

concurvity
- when one variable is a ==smooth curve== of another

$gallery$
![Image](img$6iej)

- two covariates, X1 and X2, that are not linearly related but form a perfect parabola
- if we use both X1 and X2 as predictors in a model, we get smooths with wild confidence intervals, as shown in the middle and right plots
$/gallery$

### `concurvity()` function

`concurvity()` 
- measures concurvity in model variables
- we run this function on a model object to examine the quality of our model

$acco$
`full=TRUE` mode
- reports overall concurvity for each smooth
- shows how much each smooth is predetermined by all other smooths

outputs
- function outputs **three ways** of measuring concurvity
- rule of thumb: look at the worst case, >= 0.8 = a bad value!

$code$
```r
concurvity(m1, full = true)
```

$widec$
$down
$/widec$

```r
            para s(x1) s(x2)
worst       0    0.84  0.84
observed    0    0.22  0.57
estimate    0    0.28  0.60
```

$gallery port$
$widec$
![image](img$66tv)
$/widec$

- the concurvity of the terms is high in the worst case, so we'll want to inspect the plots of our model closely and be careful in making interpretations
$/gallery port$
$/code$
$/acco$

$acco$
`full=FALSE` mode
- to be used when any values from `full=TRUE` are high
- returns matrices of pairwise concurvities
	- show the degree to which each variable is predetermined by each _other_ variable, rather than _all_ the other variables
	- can be used to pinpoint _which_ variables have a close relationship
- also outputs three measures -> look at the worst case

$code$
```r
concurvity(model, full = FALSE)
```

$widec$
$down
$/widec$

```r
$worst
      para s(X1) s(X2)
para     1  0.00  0.00
s(X1)    0  1.00  0.84
s(X2)    0  0.84  1.00
 
$observed                |  $estimate
      para s(X1) s(X2)   |        para s(X1) s(X2)
para     1  0.00  0.00   |  para     1  0.00   0.0
s(X1)    0  1.00  0.57   |  s(X1)    0  1.00   0.6
s(X2)    0  0.22  1.00   |  s(X2)    0  0.28   1.0
```
$/code$
$/acco$